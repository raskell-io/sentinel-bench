#!/usr/bin/env bash
#MISE description="Run benchmark against a proxy"
#MISE alias="b"
#MISE usage="bench <proxy> <scenario> [options]"

set -euo pipefail

# =============================================================================
# Sentinel Benchmarking Framework - Main Runner
# Usage: mise run bench <proxy> <scenario> [options]
#
# Results are stored in: results/<timestamp>_<proxy>_<scenario>/
# Each run includes comprehensive metadata for analytics and GitHub Pages.
# =============================================================================

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
ROOT_DIR="$(cd "$SCRIPT_DIR/../.." && pwd)"
RESULTS_DIR="$ROOT_DIR/results"

# Use environment variables with defaults
DURATION="${BENCH_DURATION:-60}"
CONNECTIONS="${BENCH_CONNECTIONS:-100}"
THREADS="${BENCH_THREADS:-4}"
RATE="${BENCH_RATE:-10000}"
WARMUP="${BENCH_WARMUP:-10}"
RUNS="${BENCH_RUNS:-3}"
TARGET="${BENCH_TARGET:-http://localhost:8080}"

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log_info() { echo -e "${BLUE}[INFO]${NC} $1"; }
log_success() { echo -e "${GREEN}[OK]${NC} $1"; }
log_warn() { echo -e "${YELLOW}[WARN]${NC} $1"; }
log_error() { echo -e "${RED}[ERROR]${NC} $1"; }

usage() {
    cat <<EOF
Sentinel Benchmarking Framework

Usage: mise run bench <proxy> <scenario> [options]

Proxies:
  sentinel    Sentinel reverse proxy
  envoy       Envoy proxy
  haproxy     HAProxy
  nginx       Nginx
  all         Run all proxies (comparison mode)

Scenarios:
  passthrough Basic L7 passthrough (no processing)
  routing     Multiple routes, path matching
  tls         HTTPS termination
  loadbalance Multiple backends

Options:
  --duration <secs>    Test duration (default: $DURATION)
  --connections <n>    Concurrent connections (default: $CONNECTIONS)
  --threads <n>        Worker threads (default: $THREADS)
  --rate <rps>         Target requests/second (default: $RATE)
  --warmup <secs>      Warmup duration (default: $WARMUP)
  --runs <n>           Number of runs (default: $RUNS)
  --target <url>       Target URL (default: $TARGET)
  --tool <oha|wrk2|wrk|hey|k6>  Load generator (default: auto-detect)
  --name <string>      Optional name/tag for this benchmark run
  --help               Show this help

Results are stored in: results/<timestamp>_<proxy>_<scenario>/

EOF
    exit 0
}

# =============================================================================
# Environment Detection
# =============================================================================

get_cpu_info() {
    if [[ "$OSTYPE" == "darwin"* ]]; then
        sysctl -n machdep.cpu.brand_string 2>/dev/null || echo "Unknown"
    else
        grep "model name" /proc/cpuinfo 2>/dev/null | head -1 | cut -d: -f2 | xargs || echo "Unknown"
    fi
}

get_cpu_cores() {
    if [[ "$OSTYPE" == "darwin"* ]]; then
        sysctl -n hw.ncpu 2>/dev/null || echo "0"
    else
        nproc 2>/dev/null || echo "0"
    fi
}

get_memory_gb() {
    if [[ "$OSTYPE" == "darwin"* ]]; then
        local bytes
        bytes=$(sysctl -n hw.memsize 2>/dev/null || echo "0")
        echo $((bytes / 1024 / 1024 / 1024))
    else
        free -g 2>/dev/null | awk '/^Mem:/{print $2}' || echo "0"
    fi
}

get_machine_model() {
    if [[ "$OSTYPE" == "darwin"* ]]; then
        sysctl -n hw.model 2>/dev/null || echo "Unknown"
    else
        cat /sys/class/dmi/id/product_name 2>/dev/null || echo "Unknown"
    fi
}

get_os_info() {
    if [[ "$OSTYPE" == "darwin"* ]]; then
        sw_vers -productName 2>/dev/null || echo "macOS"
    else
        cat /etc/os-release 2>/dev/null | grep "^PRETTY_NAME" | cut -d= -f2 | tr -d '"' || echo "Linux"
    fi
}

get_os_version() {
    if [[ "$OSTYPE" == "darwin"* ]]; then
        sw_vers -productVersion 2>/dev/null || echo "Unknown"
    else
        cat /etc/os-release 2>/dev/null | grep "^VERSION_ID" | cut -d= -f2 | tr -d '"' || echo "Unknown"
    fi
}

get_kernel_version() {
    uname -r 2>/dev/null || echo "Unknown"
}

get_architecture() {
    uname -m 2>/dev/null || echo "Unknown"
}

# =============================================================================
# Proxy Version Detection
# =============================================================================

get_proxy_version() {
    local proxy="$1"
    local version="unknown"

    case "$proxy" in
        sentinel)
            # Try to get version from running container or binary
            version=$(docker exec bench-sentinel sentinel --version 2>/dev/null | head -1 || echo "unknown")
            if [[ "$version" == "unknown" ]]; then
                version=$(sentinel --version 2>/dev/null | head -1 || echo "unknown")
            fi
            ;;
        envoy)
            version=$(docker exec bench-envoy envoy --version 2>/dev/null | grep -oE 'version: [0-9.]+' | cut -d' ' -f2 || echo "unknown")
            if [[ "$version" == "unknown" || -z "$version" ]]; then
                version=$(docker inspect bench-envoy 2>/dev/null | grep -oE 'envoyproxy/envoy:v[0-9.]+' | head -1 | cut -d: -f2 || echo "unknown")
            fi
            ;;
        haproxy)
            version=$(docker exec bench-haproxy haproxy -v 2>/dev/null | head -1 | grep -oE '[0-9]+\.[0-9]+\.[0-9]+' || echo "unknown")
            ;;
        nginx)
            version=$(docker exec bench-nginx nginx -v 2>&1 | grep -oE '[0-9]+\.[0-9]+\.[0-9]+' || echo "unknown")
            ;;
    esac

    echo "$version"
}

get_tool_version() {
    local tool="$1"
    local version="unknown"

    case "$tool" in
        oha)
            version=$(oha --version 2>/dev/null | grep -oE '[0-9]+\.[0-9]+\.[0-9]+' | head -1 || echo "unknown")
            ;;
        wrk2)
            version=$(wrk2 --version 2>/dev/null | head -1 || echo "unknown")
            ;;
        wrk)
            version=$(wrk --version 2>/dev/null | head -1 || echo "unknown")
            ;;
        hey)
            version=$(hey --version 2>/dev/null || echo "unknown")
            ;;
        k6)
            version=$(k6 version 2>/dev/null | grep -oE 'v[0-9]+\.[0-9]+\.[0-9]+' || echo "unknown")
            ;;
    esac

    echo "$version"
}

# =============================================================================
# Tool Detection
# =============================================================================

detect_tool() {
    if command -v oha &>/dev/null; then
        echo "oha"
    elif command -v wrk2 &>/dev/null; then
        echo "wrk2"
    elif command -v wrk &>/dev/null; then
        log_warn "Using wrk instead of wrk2 - latency may have coordinated omission"
        echo "wrk"
    elif command -v hey &>/dev/null; then
        echo "hey"
    elif command -v k6 &>/dev/null; then
        echo "k6"
    else
        log_error "No load generator found."
        log_error "Install one with: mise run install-oha  OR  mise install"
        exit 1
    fi
}

check_proxy_running() {
    local max_attempts=30
    local attempt=0

    log_info "Waiting for proxy at $TARGET..."

    while ! curl -s -o /dev/null -w "%{http_code}" "$TARGET/" 2>/dev/null | grep -qE "200|404|301|302"; do
        attempt=$((attempt + 1))
        if [ $attempt -ge $max_attempts ]; then
            log_error "Proxy not responding after ${max_attempts}s"
            return 1
        fi
        sleep 1
    done

    log_success "Proxy is ready"
    return 0
}

# =============================================================================
# Benchmark Execution
# =============================================================================

run_warmup() {
    local tool="$1"
    log_info "Running warmup for ${WARMUP}s..."

    case "$tool" in
        oha)
            oha -z "${WARMUP}s" -c 50 -q 1000 --no-tui "$TARGET/" >/dev/null 2>&1 || true
            ;;
        wrk2)
            wrk2 -t2 -c50 -d"${WARMUP}s" -R1000 "$TARGET/" >/dev/null 2>&1 || true
            ;;
        wrk)
            wrk -t2 -c50 -d"${WARMUP}s" "$TARGET/" >/dev/null 2>&1 || true
            ;;
        hey)
            hey -z "${WARMUP}s" -c 50 -q 20 "$TARGET/" >/dev/null 2>&1 || true
            ;;
        k6)
            sleep "$WARMUP"
            ;;
    esac

    log_success "Warmup complete"
}

run_benchmark_oha() {
    local output_file="$1"
    local json_file="$2"
    log_info "Running oha: ${CONNECTIONS} connections, ${RATE} RPS, ${DURATION}s"

    # Run with JSON output for machine parsing
    oha \
        -z "${DURATION}s" \
        -c "$CONNECTIONS" \
        -q "$RATE" \
        --no-tui \
        -j \
        "$TARGET/" > "$json_file" 2>&1

    # Also capture human-readable output
    oha \
        -z "${DURATION}s" \
        -c "$CONNECTIONS" \
        -q "$RATE" \
        --no-tui \
        "$TARGET/" 2>&1 | tee "$output_file"
}

run_benchmark_wrk2() {
    local output_file="$1"
    local json_file="$2"
    log_info "Running wrk2: ${THREADS} threads, ${CONNECTIONS} connections, ${RATE} RPS, ${DURATION}s"

    wrk2 \
        -t"$THREADS" \
        -c"$CONNECTIONS" \
        -d"${DURATION}s" \
        -R"$RATE" \
        --latency \
        "$TARGET/" 2>&1 | tee "$output_file"

    # wrk2 doesn't have native JSON, create a placeholder
    echo '{"tool": "wrk2", "note": "Parse from txt output"}' > "$json_file"
}

run_benchmark_wrk() {
    local output_file="$1"
    local json_file="$2"
    log_info "Running wrk: ${THREADS} threads, ${CONNECTIONS} connections, ${DURATION}s"

    wrk \
        -t"$THREADS" \
        -c"$CONNECTIONS" \
        -d"${DURATION}s" \
        --latency \
        "$TARGET/" 2>&1 | tee "$output_file"

    echo '{"tool": "wrk", "note": "Parse from txt output"}' > "$json_file"
}

run_benchmark_hey() {
    local output_file="$1"
    local json_file="$2"
    log_info "Running hey: ${CONNECTIONS} connections, ${RATE} RPS, ${DURATION}s"

    hey \
        -z "${DURATION}s" \
        -c "$CONNECTIONS" \
        -q "$((RATE / CONNECTIONS))" \
        "$TARGET/" 2>&1 | tee "$output_file"

    echo '{"tool": "hey", "note": "Parse from txt output"}' > "$json_file"
}

run_benchmark_k6() {
    local output_file="$1"
    local json_file="$2"
    log_info "Running k6: ${CONNECTIONS} VUs, ${DURATION}s"

    k6 run --quiet \
        -e TARGET="$TARGET" \
        -e DURATION="${DURATION}s" \
        -e VUS="$CONNECTIONS" \
        --summary-export="$json_file" \
        - <<'SCRIPT' 2>&1 | tee "$output_file"
import http from 'k6/http';
import { check } from 'k6';

export const options = {
    vus: __ENV.VUS ? parseInt(__ENV.VUS) : 100,
    duration: __ENV.DURATION || '60s',
};

export default function () {
    const res = http.get(__ENV.TARGET + '/');
    check(res, { 'status is 200': (r) => r.status === 200 });
}
SCRIPT
}

# =============================================================================
# Metadata Generation
# =============================================================================

generate_metadata() {
    local result_dir="$1"
    local proxy="$2"
    local scenario="$3"
    local start_time="$4"
    local end_time="$5"

    local proxy_version
    proxy_version=$(get_proxy_version "$proxy")
    local tool_version
    tool_version=$(get_tool_version "$TOOL")

    cat > "$result_dir/metadata.json" <<EOF
{
  "schema_version": "1.0.0",
  "id": "$(uuidgen 2>/dev/null || cat /proc/sys/kernel/random/uuid 2>/dev/null || date +%s%N)",
  "timestamp": {
    "start": "$start_time",
    "end": "$end_time",
    "timezone": "$(date +%Z)"
  },
  "benchmark": {
    "proxy": "$proxy",
    "scenario": "$scenario",
    "name": "${BENCH_NAME:-}",
    "config_file": "configs/${proxy}/${scenario}.kdl"
  },
  "proxy_info": {
    "name": "$proxy",
    "version": "$proxy_version",
    "container": "bench-${proxy}"
  },
  "environment": {
    "hostname": "$(hostname)",
    "machine_model": "$(get_machine_model)",
    "os": {
      "name": "$(get_os_info)",
      "version": "$(get_os_version)",
      "kernel": "$(get_kernel_version)"
    },
    "cpu": {
      "model": "$(get_cpu_info)",
      "cores": $(get_cpu_cores),
      "architecture": "$(get_architecture)"
    },
    "memory_gb": $(get_memory_gb),
    "container_runtime": "$(docker --version 2>/dev/null | head -1 || echo 'unknown')"
  },
  "test_parameters": {
    "duration_seconds": $DURATION,
    "warmup_seconds": $WARMUP,
    "connections": $CONNECTIONS,
    "threads": $THREADS,
    "target_rate": $RATE,
    "runs": $RUNS,
    "target_url": "$TARGET"
  },
  "load_generator": {
    "tool": "$TOOL",
    "version": "$tool_version"
  },
  "runs": [
$(for i in $(seq 1 "$RUNS"); do
    echo "    {\"run\": $i, \"output\": \"runs/run_${i}.txt\", \"data\": \"runs/run_${i}.json\"}$( [ $i -lt $RUNS ] && echo ',')"
done)
  ]
}
EOF
}

generate_summary() {
    local result_dir="$1"
    local proxy="$2"
    local scenario="$3"
    local start_time="$4"

    local proxy_version
    proxy_version=$(get_proxy_version "$proxy")

    cat > "$result_dir/summary.md" <<EOF
# Benchmark Results

## Overview

| Property | Value |
|----------|-------|
| **Proxy** | $proxy |
| **Version** | $proxy_version |
| **Scenario** | $scenario |
| **Date** | $start_time |
| **Machine** | $(get_machine_model) |

## Environment

| Property | Value |
|----------|-------|
| **OS** | $(get_os_info) $(get_os_version) |
| **Kernel** | $(get_kernel_version) |
| **CPU** | $(get_cpu_info) |
| **Cores** | $(get_cpu_cores) |
| **Memory** | $(get_memory_gb) GB |
| **Architecture** | $(get_architecture) |

## Test Parameters

| Parameter | Value |
|-----------|-------|
| **Duration** | ${DURATION}s |
| **Warmup** | ${WARMUP}s |
| **Connections** | $CONNECTIONS |
| **Target Rate** | $RATE RPS |
| **Runs** | $RUNS |
| **Load Generator** | $TOOL $(get_tool_version "$TOOL") |

## Results

See individual run files in \`runs/\` directory:

$(for i in $(seq 1 "$RUNS"); do
    echo "- [Run $i](runs/run_${i}.txt)"
done)

## Raw Data

- [metadata.json](metadata.json) - Machine-readable metadata
$(for i in $(seq 1 "$RUNS"); do
    echo "- [runs/run_${i}.json](runs/run_${i}.json) - Run $i data"
done)
EOF
}

# =============================================================================
# Main Benchmark Runner
# =============================================================================

run_benchmark() {
    local proxy="$1"
    local scenario="$2"

    log_info "Starting benchmark: proxy=$proxy scenario=$scenario tool=$TOOL"

    if ! check_proxy_running; then
        log_error "Cannot reach proxy. Start it first with:"
        log_error "  mise run up $proxy"
        exit 1
    fi

    # Create result directory with timestamp
    local timestamp
    timestamp=$(date +%Y%m%d_%H%M%S)
    local start_time
    start_time=$(date -Iseconds)
    local result_dir="$RESULTS_DIR/${timestamp}_${proxy}_${scenario}"
    mkdir -p "$result_dir/runs"

    log_info "Results will be saved to: $result_dir"

    run_warmup "$TOOL"

    # Run benchmarks
    for i in $(seq 1 "$RUNS"); do
        local output_file="$result_dir/runs/run_${i}.txt"
        local json_file="$result_dir/runs/run_${i}.json"

        log_info "Run $i of $RUNS"

        case "$TOOL" in
            oha)   run_benchmark_oha "$output_file" "$json_file" ;;
            wrk2)  run_benchmark_wrk2 "$output_file" "$json_file" ;;
            wrk)   run_benchmark_wrk "$output_file" "$json_file" ;;
            hey)   run_benchmark_hey "$output_file" "$json_file" ;;
            k6)    run_benchmark_k6 "$output_file" "$json_file" ;;
        esac

        if [ "$i" -lt "$RUNS" ]; then
            log_info "Cooling down for 5s..."
            sleep 5
        fi
    done

    local end_time
    end_time=$(date -Iseconds)

    # Generate metadata and summary
    generate_metadata "$result_dir" "$proxy" "$scenario" "$start_time" "$end_time"
    generate_summary "$result_dir" "$proxy" "$scenario" "$start_time"

    log_success "Benchmark complete!"
    log_success "Results: $result_dir"
    log_success "  - metadata.json (machine-readable)"
    log_success "  - summary.md (human-readable)"
    log_success "  - runs/ (individual run data)"
}

run_all_proxies() {
    local scenario="$1"
    local proxies=("sentinel" "envoy" "haproxy" "nginx")

    log_info "Running comparison benchmark for all proxies"

    for proxy in "${proxies[@]}"; do
        log_info "=== Testing $proxy ==="

        log_info "Starting $proxy..."
        docker-compose -f "$ROOT_DIR/docker/docker-compose.yaml" --profile "$proxy" up -d
        sleep 5

        run_benchmark "$proxy" "$scenario"

        log_info "Stopping $proxy..."
        docker-compose -f "$ROOT_DIR/docker/docker-compose.yaml" --profile "$proxy" down

        log_info "Cooling down for 10s..."
        sleep 10
    done

    log_success "All benchmarks complete. Results in: $RESULTS_DIR"
}

# =============================================================================
# Parse Arguments
# =============================================================================

PROXY=""
SCENARIO=""
TOOL=""
BENCH_NAME=""

while [[ $# -gt 0 ]]; do
    case $1 in
        --duration)    DURATION="$2"; shift 2 ;;
        --connections) CONNECTIONS="$2"; shift 2 ;;
        --threads)     THREADS="$2"; shift 2 ;;
        --rate)        RATE="$2"; shift 2 ;;
        --warmup)      WARMUP="$2"; shift 2 ;;
        --runs)        RUNS="$2"; shift 2 ;;
        --target)      TARGET="$2"; shift 2 ;;
        --tool)        TOOL="$2"; shift 2 ;;
        --name)        BENCH_NAME="$2"; shift 2 ;;
        --help|-h)     usage ;;
        -*)            log_error "Unknown option: $1"; usage ;;
        *)
            if [ -z "$PROXY" ]; then
                PROXY="$1"
            elif [ -z "$SCENARIO" ]; then
                SCENARIO="$1"
            fi
            shift
            ;;
    esac
done

if [ -z "$PROXY" ] || [ -z "$SCENARIO" ]; then
    log_error "Missing required arguments: proxy and scenario"
    usage
fi

# Auto-detect tool if not specified
if [ -z "$TOOL" ]; then
    TOOL=$(detect_tool)
fi

mkdir -p "$RESULTS_DIR"

if [ "$PROXY" = "all" ]; then
    run_all_proxies "$SCENARIO"
else
    run_benchmark "$PROXY" "$SCENARIO"
fi
